{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yDFLWNXCBwfu"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy as nltk_accuracy\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the movie_reviews dataset\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load movie reviews from nltk\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "# Shuffle the documents\n",
        "random.shuffle(documents)\n",
        "\n",
        "# Define a feature extractor\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in movie_reviews.words():\n",
        "        features[f'contains({word})'] = (word in document_words)\n",
        "    return features\n",
        "\n",
        "# Extract features for all documents\n",
        "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Evaluate the classifier\n",
        "print(f'Accuracy: {nltk_accuracy(classifier, test_set):.2f}')\n",
        "\n",
        "# Show the most informative features\n",
        "classifier.show_most_informative_features(10)\n",
        "\n",
        "# Function to classify a custom review\n",
        "def classify_review(review):\n",
        "    tokens = word_tokenize(review.lower())\n",
        "    features = document_features(tokens)\n",
        "    return classifier.classify(features)\n",
        "\n",
        "# Test the classifier with custom reviews\n",
        "custom_reviews = [\n",
        "    \"This movie was amazing! The acting was great, plot was wonderful.\",\n",
        "    \"I hated this movie. It was boring and too long.\",\n",
        "    \"An average movie with decent performances but a weak storyline.\"\n",
        "]\n",
        "\n",
        "for review in custom_reviews:\n",
        "    print(f'Review: {review}\\nSentiment: {classify_review(review)}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZcNyUjHB7vY",
        "outputId": "43f56f86-7463-4111-a646-fc06eb47b0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    }
  ]
}